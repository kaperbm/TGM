---
title: "Statistische Modellierung"
author: "Kacper Bohaczyk"
date: "2024-12-22"
output: pdf_document
---

```{r setup, include=FALSE}
knitr::opts_chunk$set(echo = TRUE)
```

### Aufgabe 1

Das Dataset zeigt eine Auswahl an Daten über die 50 Staaten der USA an. \hfill \break
Bevölkerung in 100 Tausenden, \hfill \break
Einkommen pro Person in USD, \hfill \break
Analphabetenrate als Prozent der Bevölkerung, \hfill \break
Lebenserwartung in Jahren, \hfill \break
Mord und Totschlag pro 100 Tausend Einwohner, \hfill \break
Menschen mit High-School abschlüssen als Prozent der Bevölkerung, \hfill \break
Tage mit Temperatur unter 0° C in großen Städten (1931-1960),  \hfill \break
Fläche der Staaten in Quadratmeilen.



```{r}
?state.x77
summary(state.x77)
```

``` {r test}
invisible(library(lmtest))
invisible(library(ggplot2))



modell <- lm(state.x77[,"Murder"] ~ state.x77[,"Life Exp"] + state.x77[,"Population"] + state.x77[,"Illiteracy"] + state.x77[,"Income"])
predicted_values <- predict(modell)
plot(state.x77[,"Murder"], predicted_values, 
     xlab = "Tatsächliche Werte", ylab = "Vorhergesagte Werte", 
     main = "Tatsächliche vs Vorhergesagt Werte")
abline(0, 1,col = "red")#


invisible(library(relaimpo))
calc.relimp(modell, type = "lmg")
plot(modell)
 ## Plottet die 4 Diagramme


panel.hist <- function(x, ...) {
    usr <- par("usr"); on.exit(par(usr))
    par(usr = c(usr[1:2], 0, 1.5))
    h <- hist(x, plot = FALSE)
    breaks <- h$breaks; nB <- length(breaks)
    y <- h$counts; y <- y/max(y)
    rect(breaks[-nB], 0, breaks[-1], y, col = "violet", ...)
}

panel.cor <- function(x, y, digits = 2, prefix = "", cex.cor, ...) {
    usr <- par("usr"); on.exit(par(usr))
    par(usr = c(0, 1, 0, 1))
    r <- abs(cor(x, y))
    txt <- format(c(r, 0.123456789), digits = digits)[1]
    txt <- paste0(prefix, txt)
    if(missing(cex.cor)) cex.cor <- 0.8/strwidth(txt)
    text(0.5, 0.5, txt, cex = cex.cor * r)
}

# Create a matrix of scatterplots
pairs(state.x77[, c("Life Exp" , "Population" , "Illiteracy", "Income")], 
      lower.panel = panel.smooth, 
      upper.panel = panel.cor, 
      diag.panel = panel.hist, 
      las=1)


```
Das Modell vorhersagt sinnvoll die Daten.

Die Residuen zeigen eine Normalverteilung, bedinden sich um den Wert 0 und weisen kein Muster auf.

Zwischen Analphabetismus und Lebenserwartung gibt es  Multikollinearität.

Modellselektion der relevanten erklärenden Variablen durch
```{r neuesModel}
modellNew <- lm(state.x77[,"Murder"] ~ state.x77[,"Population"] + state.x77[,"Life Exp"] + state.x77[,"Income"])
predicted_values <- predict(modellNew)
plot(state.x77[,"Murder"], predicted_values, 
     xlab = "Tatsächliche Werte", ylab = "Vorhergesagte Werte", 
     main = "Tatsächliche vs Vorhergesagt Werte")
abline(0, 1, col="red")#


invisible(library(relaimpo))
calc.relimp(modellNew, type = "lmg")

panel.hist <- function(x, ...) {
    usr <- par("usr"); on.exit(par(usr))
    par(usr = c(usr[1:2], 0, 1.5))
    h <- hist(x, plot = FALSE)
    breaks <- h$breaks; nB <- length(breaks)
    y <- h$counts; y <- y/max(y)
    rect(breaks[-nB], 0, breaks[-1], y, col = "violet", ...)
}

panel.cor <- function(x, y, digits = 2, prefix = "", cex.cor, ...) {
    usr <- par("usr"); on.exit(par(usr))
    par(usr = c(0, 1, 0, 1))
    r <- abs(cor(x, y))
    txt <- format(c(r, 0.123456789), digits = digits)[1]
    txt <- paste0(prefix, txt)
    if(missing(cex.cor)) cex.cor <- 0.8/strwidth(txt)
    text(0.5, 0.5, txt, cex = cex.cor * r)
}

# Create a matrix of scatterplots
pairs(state.x77[, c("Life Exp" , "Population" , "Income")], 
      lower.panel = panel.smooth, 
      upper.panel = panel.cor, 
      diag.panel = panel.hist, 
      las=1)




```


Das Modell vorhersagt sinnvoll die Daten.

Die Residuen zeigen eine Normalverteilung, bedinden sich um den Wert 0 und weisen kein Muster auf.

Zwischen Analphabetismus und Lebenserwartung gibt es  Multikollinearität.

Zwischen Life Exp und Income. gibt es  Multikollinearität.

Einkommen ist ein unwichtiger Parameter

### Aufgabe 2
``` {r test1, echo=FALSE}
library(MASS)
library(ggplot2)

data(Pima.tr)
model <- glm(type ~ skin + glu  + bmi + ped + bp + age + npreg, family=binomial(link ="logit"), data=Pima.tr)



# Create a matrix of scatterplots
pairs(Pima.tr[, c(  "glu"  , "bmi" , "ped" , "bp"   , "age")], 
      lower.panel = panel.smooth, 
      upper.panel = panel.cor, 
      diag.panel = panel.hist, 
      las=1)



summary(model)
coef(model)


model <- glm(type ~ skin + glu   + ped + bp  + npreg, family=binomial(link ="logit"), data=Pima.tr)
# Create a matrix of scatterplots
pairs(Pima.tr[, c("npreg" ,  "glu"  , "bmi" , "ped" , "bp"  )], 
      lower.panel = panel.smooth, 
      upper.panel = panel.cor, 
      diag.panel = panel.hist, 
      las=1)
summary(model)
coef(model)

model <- glm(type ~ glu  + bmi + ped + bp + age , family=binomial(link ="logit"), data=Pima.tr)
# Create a matrix of scatterplots
pairs(Pima.tr[, c("glu"  , "bmi" , "ped" , "bp"  , "age")], 
      lower.panel = panel.smooth, 
      upper.panel = panel.cor, 
      diag.panel = panel.hist, 
      las=1)
summary(model)
coef(model)

```
Erstes Modell mit Kolinearität:
f = -9.773+0.103*npreg+0.032*glu-0.005*bp-0.002*skin+0.084*bmi+1.820*ped+0.041*age

Zweites Modell (ohne age & bmi):
f = -7.861769961 + skin*0.027693775 + glu*0.034494923 + ped*1.833900379 + bp*0.006462532 + npreg*0.160033092

Drittes Modell (ohne npreg & skin):
f = -9.762936794 + glu* 0.031583880 + bmi*0.078722179 + ped*1.729202382 + bp*-0.005174239 + age*0.060534977

Das zweite Model ist l am sinnvollsten, da es am wenigsten Kolinearität aufweist.

Die einzelnen Daten wirken sich beim zweiten Modell so aus:

Pro mm Tricep Fettschicht dicke erhöt sich die Wahrscheinlichkeit um 28%

Pro Miligramm Plama Glucose pro Deziliter steigt die Diabetis Wahrscheinlickeit um 35%

Pro Erhöhung der "diabetes pedigree function." um 1 steigt die Wahrscheinlichkeit um 625%

Pro Erhöhung des Blutdrucks um 1 mmHg steigt die Wahrscheinlichkeit um 0.6%

Pro Schwangerschaft erhöt sich das Risisko um 17%

Diese Werte im Kontext bedeuten, dass der mit Abstand wichtigste Wert der der DPF, also wie stark man für Diabetes anfällig ist. 

In der Summary sieht man, dass sich die Wichtigkeit der Daten stark ändert wenn man die Kolinearität entfernt.

